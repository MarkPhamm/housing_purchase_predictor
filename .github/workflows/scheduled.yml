name: 🔄 Scheduled Maintenance

on:
  schedule:
    # Run every Monday at 9 AM UTC
    - cron: '0 9 * * 1'
  workflow_dispatch:  # Allow manual trigger

jobs:
  # Weekly model retraining
  retrain-model:
    name: 🤖 Weekly Model Retraining
    runs-on: ubuntu-latest
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v5
      
    - name: 🐍 Set up Python
      uses: actions/setup-python@v6
      with:
        python-version: '3.9'
        cache: 'pip'
        
    - name: 📦 Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: 🚀 Retrain model
      run: |
        cd src
        python main_pipeline.py
        
    - name: 📊 Check model performance
      run: |
        cd src
        python -c "
        import pandas as pd
        from predict import HousePurchasePredictor
        from pathlib import Path
        
        # Load latest model
        models_dir = Path('../models')
        model_files = list(models_dir.glob('best_model_*.pkl'))
        latest = max(model_files, key=lambda x: x.stat().st_mtime)
        parts = latest.stem.split('_')
        timestamp = '_'.join(parts[-2:])
        
        predictor = HousePurchasePredictor(
            model_path=str(latest),
            scaler_path=str(models_dir / f'scaler_{timestamp}.pkl'),
            encoders_path=str(models_dir / f'encoders_{timestamp}.pkl'),
            feature_names_path=str(models_dir / f'feature_names_{timestamp}.json')
        )
        
        print('✅ Model retrained successfully')
        print(f'Model timestamp: {timestamp}')
        "
        
    - name: 📤 Upload new model
      uses: actions/upload-artifact@v4
      with:
        name: retrained-model-${{ github.run_number }}
        path: models/
        retention-days: 7

  # Dependency security check
  security-check:
    name: 🔒 Security Check
    runs-on: ubuntu-latest
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v5
      
    - name: 🐍 Set up Python
      uses: actions/setup-python@v6
      with:
        python-version: '3.9'
        cache: 'pip'
        
    - name: 📦 Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install safety
        
    - name: 🔍 Check for security vulnerabilities
      run: |
        safety check --json --output safety-report.json || true
        
        # Check if there are any high/critical vulnerabilities
        if jq '.vulnerabilities | length' safety-report.json > 0; then
          echo "⚠️ Security vulnerabilities found:"
          cat safety-report.json
          echo "::warning::Security vulnerabilities detected in dependencies"
        else
          echo "✅ No security vulnerabilities found"
        fi
        
    - name: 📊 Update dependencies
      run: |
        # Update pip
        python -m pip install --upgrade pip
        
        # Update requirements if needed
        pip install --upgrade -r requirements.txt
        
        # Generate new requirements if any packages were updated
        pip freeze > requirements-updated.txt
        
        if ! diff requirements.txt requirements-updated.txt > /dev/null; then
          echo "📦 Dependencies updated:"
          diff requirements.txt requirements-updated.txt || true
          echo "::notice::Consider updating requirements.txt with new versions"
        else
          echo "✅ All dependencies are up to date"
        fi

  # Documentation check
  docs-check:
    name: 📚 Documentation Check
    runs-on: ubuntu-latest
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v5
      
    - name: 📋 Check documentation completeness
      run: |
        echo "Checking documentation files..."
        
        # Check if all required docs exist
        docs=(
          "README.md"
          "app/README.md"
          "APP_GUIDE.md"
          "QUICKSTART.md"
          "app/TROUBLESHOOTING.md"
          "FIXES_APPLIED.md"
          "QUICK_REFERENCE.md"
        )
        
        missing_docs=()
        for doc in "${docs[@]}"; do
          if [ ! -f "$doc" ]; then
            missing_docs+=("$doc")
          fi
        done
        
        if [ ${#missing_docs[@]} -eq 0 ]; then
          echo "✅ All documentation files present"
        else
          echo "❌ Missing documentation files:"
          printf '%s\n' "${missing_docs[@]}"
          echo "::warning::Some documentation files are missing"
        fi
        
    - name: 📊 Check documentation quality
      run: |
        # Check README length (should be substantial)
        readme_lines=$(wc -l < README.md)
        if [ "$readme_lines" -lt 50 ]; then
          echo "⚠️ README.md seems too short ($readme_lines lines)"
          echo "::warning::README.md might need more content"
        else
          echo "✅ README.md has good length ($readme_lines lines)"
        fi
        
        # Check if main README has key sections
        if grep -q "## Installation" README.md && \
           grep -q "## Usage" README.md && \
           grep -q "## Features" README.md; then
          echo "✅ README.md has key sections"
        else
          echo "⚠️ README.md missing key sections"
          echo "::warning::README.md should include Installation, Usage, and Features sections"
        fi

  # Performance monitoring
  performance-check:
    name: ⚡ Performance Check
    runs-on: ubuntu-latest
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v5
      
    - name: 🐍 Set up Python
      uses: actions/setup-python@v6
      with:
        python-version: '3.9'
        cache: 'pip'
        
    - name: 📦 Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: ⚡ Test performance benchmarks
      run: |
        cd src
        python -c "
        import time
        import pandas as pd
        from predict import HousePurchasePredictor
        from pathlib import Path
        
        # Load model
        models_dir = Path('../models')
        model_files = list(models_dir.glob('best_model_*.pkl'))
        if not model_files:
          print('❌ No model found, training first...')
          import subprocess
          subprocess.run(['python', 'main_pipeline.py'])
          model_files = list(models_dir.glob('best_model_*.pkl'))
        
        latest = max(model_files, key=lambda x: x.stat().st_mtime)
        parts = latest.stem.split('_')
        timestamp = '_'.join(parts[-2:])
        
        predictor = HousePurchasePredictor(
            model_path=str(latest),
            scaler_path=str(models_dir / f'scaler_{timestamp}.pkl'),
            encoders_path=str(models_dir / f'encoders_{timestamp}.pkl'),
            feature_names_path=str(models_dir / f'feature_names_{timestamp}.json')
        )
        
        # Create test data
        test_data = pd.DataFrame({
            'property_id': [1],
            'country': ['USA'],
            'city': ['New York'],
            'property_type': ['Apartment'],
            'furnishing_status': ['Fully-Furnished'],
            'property_size_sqft': [2000],
            'price': [500000],
            'constructed_year': [2010],
            'previous_owners': [2],
            'rooms': [3],
            'bathrooms': [2],
            'garage': [1],
            'garden': [0],
            'crime_cases_reported': [0],
            'legal_cases_on_property': [0],
            'customer_salary': [100000],
            'loan_amount': [400000],
            'loan_tenure_years': [30],
            'monthly_expenses': [3000],
            'down_payment': [100000],
            'emi_to_income_ratio': [0.3],
            'satisfaction_score': [7],
            'neighbourhood_rating': [7],
            'connectivity_score': [7]
        })
        
        # Benchmark prediction speed
        times = []
        for i in range(100):
          start = time.time()
          result = predictor.predict(test_data)
          end = time.time()
          times.append(end - start)
        
        avg_time = sum(times) / len(times)
        max_time = max(times)
        min_time = min(times)
        
        print(f'📊 Performance Metrics:')
        print(f'  Average: {avg_time*1000:.2f}ms')
        print(f'  Min: {min_time*1000:.2f}ms')
        print(f'  Max: {max_time*1000:.2f}ms')
        
        # Performance thresholds
        if avg_time > 1.0:
          print('⚠️ Warning: Average prediction time > 1s')
          print('::warning::Prediction performance degraded')
        elif avg_time > 0.5:
          print('⚠️ Notice: Average prediction time > 500ms')
          print('::notice::Consider optimizing prediction speed')
        else:
          print('✅ Performance is good')
        "

  # Generate weekly report
  weekly-report:
    name: 📊 Weekly Report
    runs-on: ubuntu-latest
    needs: [retrain-model, security-check, docs-check, performance-check]
    if: always()
    
    steps:
    - name: 📊 Generate weekly report
      run: |
        echo "# 📊 Weekly Maintenance Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## 📅 Report Date" >> $GITHUB_STEP_SUMMARY
        echo "$(date)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## ✅ Task Status" >> $GITHUB_STEP_SUMMARY
        echo "- **Model Retraining**: ${{ needs.retrain-model.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Security Check**: ${{ needs.security-check.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Documentation Check**: ${{ needs.docs-check.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Performance Check**: ${{ needs.performance-check.result }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## 🔍 Summary" >> $GITHUB_STEP_SUMMARY
        echo "Weekly maintenance completed. Check individual job results for details." >> $GITHUB_STEP_SUMMARY
